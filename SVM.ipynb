{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)\n",
    "This document will look at implementing the SVM Model on a subset of the Titanic Dataset to classify individuals survived or perished in the disaster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Observations: 891\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_titanic_df = pd.read_csv(r'data\\partial_titanic.csv')\n",
    "print(\"Number of Observations: \" + str(raw_titanic_df.iloc[:,1].count()))\n",
    "raw_titanic_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Features & Preprocessing\n",
    "I will select some features that do not require a lot of engineering to be compatible with the model.\n",
    "To Note:\n",
    "- EDA not performed, undertaken an understanding of this dataset in other documents.\n",
    "- Simple Selection to demonstrate the Logitic Regression Classifier.\n",
    "- Pclass and Gender will be one-hot-encoded\n",
    "- All features will be scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass        0\n",
      "Sex           0\n",
      "Age         177\n",
      "Fare          0\n",
      "Survived      0\n",
      "dtype: int64\n",
      "Length before NaN drop: 891\n"
     ]
    }
   ],
   "source": [
    "# Select a subset of features\n",
    "sub_titanic_df = raw_titanic_df[[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Survived\"]].copy()\n",
    "print(sub_titanic_df.isna().sum())\n",
    "print(\"Length before NaN drop: \" + str(sub_titanic_df.iloc[:, 1].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length After NaN drop: 714\n"
     ]
    }
   ],
   "source": [
    "# Drop NaN's from Age column which is the only column they exist in\n",
    "sub_titanic_df = sub_titanic_df[sub_titanic_df[\"Age\"].notna()]\n",
    "print(\"Length After NaN drop: \" + str(sub_titanic_df.iloc[:, 1].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Dependant Variables: \n",
      "   Pclass     Sex   Age     Fare\n",
      "0       3    male  22.0   7.2500\n",
      "1       1  female  38.0  71.2833\n",
      "2       3  female  26.0   7.9250\n",
      "3       1  female  35.0  53.1000\n",
      "4       3    male  35.0   8.0500\n",
      "\n",
      "y Target Predictor (Survived): \n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split Target and Dependant Variables\n",
    "X = sub_titanic_df.iloc[:, :-1]\n",
    "y = sub_titanic_df.iloc[:, -1]\n",
    "\n",
    "print(\"X Dependant Variables: \")\n",
    "print(str(X.head()) + \"\\n\")\n",
    "print(r\"y Target Predictor (Survived): \")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# 0 & 1 as thats the index of the columns to transform\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0,1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "# Scale Train and Test sets by the Scaler that knows the Training Data\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Dependant Variables One-Hot-Encoded & Feature Scaled: \n",
      "[[-0.59534056  1.80167471 -1.00562329 -0.75426451  0.75426451 -0.44288641\n",
      "  -0.36401192]\n",
      " [-0.59534056 -0.55503915  0.99440816 -0.75426451  0.75426451 -0.92142214\n",
      "  -0.49818747]\n",
      " [-0.59534056 -0.55503915  0.99440816 -0.75426451  0.75426451  0.24073606\n",
      "  -0.48196269]\n",
      " [-0.59534056  1.80167471 -1.00562329  1.32579484 -1.32579484  0.3090983\n",
      "  -0.40176517]\n",
      " [-0.59534056 -0.55503915  0.99440816 -0.75426451  0.75426451 -0.64797316\n",
      "  -0.49541937]]\n",
      "\n",
      "y Target Predictor (Survived): \n",
      "135    0\n",
      "764    0\n",
      "103    0\n",
      "576    1\n",
      "664    1\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train Dependant Variables One-Hot-Encoded & Feature Scaled: \")\n",
    "print(str(X_train[0:5]) + \"\\n\")\n",
    "print(r\"y Target Predictor (Survived): \")\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Linear SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the SVM model on the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear')\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[84 19]\n",
      " [28 48]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7374301675977654"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building  SVM With Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid=[{'C': [10, 100, 1000], 'gamma': [0.01, 0.1, 0.5],\n",
       "                          'kernel': ['rbf', 'linear']}])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the parameters by cross-validation\n",
    "parameters = [{'kernel': ['rbf', 'linear'],\n",
    "                'gamma': [0.01, 0.1, 0.5],\n",
    "                'C': [10, 100, 1000]}]\n",
    "print(\"# Tuning hyper-parameters\")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Fit Classifier with Grid Search CV\n",
    "classifier = GridSearchCV(SVC(), parameters, cv=5)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:\n",
      "{'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Best Parameters\n",
    "print('best parameters:')\n",
    "print(classifier.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90 13]\n",
      " [25 51]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7877094972067039"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Combinations:\n",
      "-------------------------------------\n",
      "0.785 (+/-0.037) for {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.068) for {'C': 10, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "0.813 (+/-0.065) for {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.068) for {'C': 10, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "0.809 (+/-0.063) for {'C': 10, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.068) for {'C': 10, 'gamma': 0.5, 'kernel': 'linear'}\n",
      "0.781 (+/-0.044) for {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.068) for {'C': 100, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "0.806 (+/-0.045) for {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.068) for {'C': 100, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "0.804 (+/-0.067) for {'C': 100, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.068) for {'C': 100, 'gamma': 0.5, 'kernel': 'linear'}\n",
      "0.802 (+/-0.069) for {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.068) for {'C': 1000, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "0.817 (+/-0.061) for {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.068) for {'C': 1000, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "0.789 (+/-0.044) for {'C': 1000, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.068) for {'C': 1000, 'gamma': 0.5, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# List of All Combinations\n",
    "print(\"All Combinations:\")\n",
    "print('-------------------------------------')\n",
    "means = classifier.cv_results_['mean_test_score']\n",
    "stds = classifier.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, classifier.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
